#### new improved YYT
1. **rewrote **
    - agents.yaml
    - tasks.yaml
    - custom_tool.py
    - crew.py
    - main.py

2. to save the report with date and time stamp so that we can compare the reports generated by LLM models used.
***if other location ***
output_file=f"C:/Users/Srika/Desktop/Reports/Report-{suffix_datetime}.md"

```
    result = crew.crew().kickoff(inputs=inputs)
    print("Analysis Result:")
    print(result) #.encode("utf-8"))

    # new code as follows

    # Get the current date and time
    current_datetime = datetime.now()
    # Format the date and time in a specific format, e.g., YYYY-MM-DD_HH-MM
    formatted_datetime = current_datetime.strftime("%Y-%m-%d_%H-%M")
    # Use the formatted date and time in the filename
    filename = f"Report_{formatted_datetime}.md"

    # print(f"Writing to {filename}") # Check the path where the file is being written

    # Open a new file with the dynamic filename in write mode
    with open(filename, 'w', encoding='utf-8') as file:
        # Write the Markdown content to the file
        file.write(result)
        file.flush()  # Ensure data is written to the disk; maybe not necessary
```

3. made it easy to select the LLM

use ctrl / to uncomment and commnent

```
        # # Groq
        # self.custom_llm = ChatGroq(
        #     temperature=0,
        #     groq_api_key=os.environ.ge("GROQ_API_KEY"),
        #     model_name="llama3-70b-8192",
        # )

        # # OPenAI
        # self.custom_llm = ChatOpenAI(
        #     temperature=0,
        #     api_key=os.environ.get("OPENAI_API_KEY"),
        #     model_name="gpt-3.5-turbo",
        # )

        # Ollama
        self.custom_llm = ChatOpenAI(
            model="mistral",
            #model="nous-hermes2pro-llama3-8b", nope does not work
            #model="openhermes", #goes into loops, don't use
            base_url="http://localhost:11434/v1",
            api_key="ollama",  # something random
            temperature=0,
        )

```
